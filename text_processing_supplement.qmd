---
title: "Text Processing Supplement"
format: html
editor: visual
---

## Part 1: Pre-processing

### Import libraries
```{r libraries}
library(tidyverse)
library(tidytext)
library(stringi)
library(qdapRegex )
```

```{r rmdformats, include=FALSE}
library(rmdformats)
```


### Import the full text of *Absalom, Absalom!*

*Note*: Due to copyright the full text of *Absalom, Absalom!* has been left out of the repository. 

```{r import_refined_text_files}

all_works_refined <-
  list.files(file.path("refined_text_data"), full.names = TRUE, pattern = "*.txt") %>% #grab a list of all the files with .txt extension
  #the full.names value needs to set to TRUE to get the full path. For some reason you will get a "permission denied" error if you do not do this.
  map_df(~ tibble(  #the map function performs the same command on all parts of the data set. In this case the .txt files
    text = read_file(.), #read the files
    date = ifelse(
      str_detect(basename(.), "[:digit:]{4}") == TRUE,
      str_extract(basename(.), "[:digit:]{4}"),
      NA), #see if there is a date in yyyy format, i.e. 1987, and extract the date, if it can't find date NA
    title=str_extract(basename(.), "(?<=_)[:alpha:]*"),
    code=str_extract(basename(.), "[:upper:]+"),
    revised = str_detect(basename(.),"_revised")
  )) 
 
```


```{r}
#This is temporary to check data

all_works_refined <- all_works_refined %>%
                      filter( code !="R") %>% 
filter( code!="RQ") %>% 
                           mutate(text = rm_abbreviation(text, replacement = "abbreviationremoved ")) %>% 
  mutate(text = str_replace_all(text, "Mr\\.", "Mr ")) %>%
  mutate(text = str_replace_all(text, "Mrs\\.", "Mrs ")) %>% 
  mutate(text = str_replace_all (text, "\\.\\.\\.", " punctellipse ")) %>%
  mutate(text = str_replace_all (text, "\\.\\s\\.\\s\\.\\s", " punctellipse ")) %>% 
  mutate(text = str_replace_all(text,"\u2026", " punctellipse "))


```

```{r}
actual_ellipse <- all_works_refined %>%
                  group_by(code) %>% 
                  mutate(real_ellipse=str_count(text,"\u2026")) %>% 
                          select(!text)
```



```{r}
all_works_tidy_string <- all_works_refined %>%
  group_by(title, date, code) %>% 
  #mutate(text = gsub("[‘’]", "'", text)) %>% 
  mutate(text =str_squish(text)) %>%
  mutate(text = str_replace_all(text, "—", " - ")) %>%  
  mutate(work_length = str_count(text, "\\S+")) %>%
  mutate(type = ifelse(work_length > 40000, "novel", "short_story")) %>% 
  mutate(cleaned = str_to_lower(text)) %>% 
  
  mutate(cleaned = str_replace_all(cleaned, "\\p{Punct}", "p"))
  
  
  

```

```{r}
# cleaned_text <- all_works_tidy_string %>% 
#                   unnest_tokens(text, text) %>%
#   summarize(cleaned = str_c(text, collapse = " ")) %>% 
#                 select(code, cleaned)
```




```{r}
dy_works_tidy_short <- all_works_tidy_string %>% 
                      filter(code!="ZZ") %>% 
                      filter(code!="RQ") 


```

```{r}

```


```{r}
# Import dy_event_data and change column names to eliminate capital letters and spaces.

dy_events_data <- read_csv("processed_data/dy_database_flattened_2023_6_29.csv") %>% 
                  rename_with( ~ tolower(str_replace_all(.x,"\\s+|\\p{Punct}", "_")))
                  
```

```{r}
#Clean up the event data and build begin and end word vectors

dy_events_data_short <- dy_events_data %>%
  select(sourcetexttitle,
         sourcetextcode,
         first_8_10_words_of_event,
         nid,
         orderwithinpage) %>%
  rename(begin_word = first_8_10_words_of_event)  %>%
  relocate(begin_word, .after = last_col()) %>%
  mutate(begin_word = rm_abbreviation(begin_word, replacement = "abbreviationremoved ")) %>%
  mutate(begin_word = str_replace_all(begin_word, "Mr\\.", "Mr ")) %>%
  mutate(begin_word = str_replace_all(begin_word, "Mrs\\.", "Mrs ")) %>%
  mutate(begin_word = str_replace_all (begin_word, "\\.\\.\\.", " punctellipse ")) %>%
  mutate(begin_word = str_replace_all (begin_word, "\\.\\s\\.\\s\\.\\s", " punctellipse ")) %>%
  mutate(begin_word = str_replace_all(begin_word, "\u2026", " punctellipse ")) %>% 
mutate(begin_word = str_replace_all(begin_word, "—", " - ")) %>%
  rename(code = sourcetextcode) %>%
  distinct(nid, .keep_all = TRUE) %>%
  group_by(sourcetexttitle) %>%
  arrange(orderwithinpage, .by_group =
            TRUE) %>%
  mutate(end_word = ifelse(code ==
                             lead(code), lead(begin_word), ""),
         .after = begin_word) %>%
  mutate(end_word = ifelse(is.na(end_word), "END_END_END", end_word)) %>%
  mutate(begin_word_cleaned = str_to_lower(str_squish(begin_word))) %>%
  mutate(end_word_cleaned = str_to_lower(str_squish(end_word))) %>%
  mutate(begin_word_cleaned = str_replace_all(begin_word_cleaned, "\\p{Punct}", "p")) %>%
  mutate(end_word_cleaned = str_replace_all(end_word_cleaned, "\\p{Punct}", "p")) %>%
  ungroup()

```





```{r}
dy_texts_events <-  dy_works_tidy_short %>% 
                    left_join(dy_events_data_short, by="code")
```


```{r}
dy_text_event_indexed <- dy_texts_events %>% 
                          mutate(begin_index = str_locate(cleaned, begin_word_cleaned)[,1]) %>% 
                          mutate(end_index = str_locate(cleaned, end_word_cleaned)[,1])
```

```{r}
dy_text_event_indexed_aa_text <-  dy_text_event_indexed %>% 
                                  filter(code=="AA") %>% 
                                  distinct(cleaned)
```

```{r}
write_lines(dy_text_event_indexed_aa_text$cleaned,"absalom_sample.txt")
```


```{r}
dy_text_event_indexed_NA <- dy_text_event_indexed %>% 
                            filter(is.na(begin_index)) %>% 
                            select(begin_word,begin_word_cleaned, orderwithinpage)
```

```{r}
dy_text_event_sentences <- dy_text_event_indexed %>% 
                            mutate(sentence = str_sub(text,begin_index,end_index-1))
```



```{r}
all_works_sentence_index <- all_works_tidy_string %>% 
                            
                            group_by(code,date) %>% 
                            rowwise() %>%
  mutate(sentences = str_extract_all(text, "[^.!?]+[.!?]+\"?")) %>%
  unnest(cols = sentences) %>% 
  select(!text) %>% 
  select(!cleaned) %>% 
   mutate(sentence_index=row_number()) %>% 
  group_by(code, sentences, sentence_index) %>% 
  unnest_characters(characters, sentences, strip_non_alphanum = FALSE, to_lower = FALSE, drop= FALSE) %>% 
  group_by(code) %>% 
  select(!characters) %>% 
  mutate(begin_sentence_index = row_number()) %>% 
  distinct(sentences, .keep_all = TRUE) %>% 
  mutate(end_sentence_index = lead(begin_sentence_index)-1) %>% 
  mutate(end_sentence_index = if_else(is.na(end_sentence_index),begin_sentence_index+str_length(sentences),end_sentence_index)) %>% 
  mutate(string_length = str_count(sentences, pattern="\\s+"))
                               
```


```{r}
dy_text_event_sentences_compact <- dy_text_event_sentences %>% 
                                    select(!c(text,cleaned))


```


```{r}
sentences_in_events <- all_works_sentence_index %>%
  inner_join(dy_text_event_sentences_compact, by = NULL, copy = TRUE) %>%
  filter(begin_sentence_index >= begin_index, end_sentence_index <= end_index) %>% 
  select(!c(begin_word_cleaned, end_word_cleaned))
```

```{r}
demographic <- read_csv("processed_data/dy_database_flattened_2023_6_29.csv")
```

```{r}
short_demographic <- demographic %>%
  select(
    SourceTextTitle,
    SourceTextCode,
    PageNumber,
    Nid,
    PresentMentioned,
    Race,
    Gender,
    Class,
    Rank,
    IndividualGroup
    ) %>%
  filter(PresentMentioned == "Present") %>%
  filter(IndividualGroup=="Individual") %>% 
  filter(str_detect(Gender,"Group",negate= TRUE))
```


```{r}

race_demographic <- short_demographic %>%
  group_by(SourceTextCode, Nid) %>%
  pivot_wider(
    id_cols = c(SourceTextCode, PageNumber, Nid),
    names_from = Race,
    values_from = Gender,
    values_fn = list(Gender = length),
    names_prefix = "race_"
  )  
       
```


```{r}
raceclassgender_demographic <- short_demographic %>%
  mutate(race_class_gender = paste(Race, Class, Gender, sep ="_")) %>%
  mutate(race_class_gender = tolower(str_replace_all(race_class_gender, " ", "_"))) %>%
  group_by(SourceTextCode, Nid) %>%
  pivot_wider(
    id_cols = c(SourceTextCode, PageNumber, Nid),
    names_from = race_class_gender,
    values_from = Gender,
    values_fn = list(Gender = length),
    names_prefix = "all_"
  ) %>%
  rename_with( ~ tolower(gsub(" ", "_", .x, fixed = TRUE))) %>%
  ungroup()
```

```{r}
sentence_demographics <- sentences_in_events %>% 
                          left_join(raceclassgender_demographic, by="nid") %>% 
mutate(across(starts_with("all"), ~ . * string_length))


```

```{r}
average_sentence_length <- sentence_demographics %>% 
                            ungroup() %>% 
                            filter(code!="RQ") %>% 
                            select(starts_with("all")) %>%
  summarise(across(everything(), list(mean = ~mean(.x, na.rm = TRUE),
                                      median = ~median(.x, na.rm = TRUE),
                                       max = ~max(.x, na.rm = TRUE),
                                      sum = ~sum(.x, na.rm = TRUE)))) %>% 
   pivot_longer(cols = everything(), 
               names_to = c("variable", "statistic"), 
               names_pattern = "(.+)_(.+)") %>%
  pivot_wider(names_from = "statistic", values_from = "value")
  

```

